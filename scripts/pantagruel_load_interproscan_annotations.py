#!/usr/bin/python
# -*- coding: utf-8 -*-
import glob, os, sys, getopt
from ptg_utils import get_dbconnection

# input is expected from a TSV table file generated by interproscan program
# when ran with options '--iprlookup --go_terms --pathways'
# the table should contain the following fields:
	#~ nr_protein_id varchar(20) not null,
	#~ sequence_md5_digest text not null,
	#~ sequence_length smallint not null,
	#~ analysis_method text not null,
	#~ signature_accession text not null,
	#~ signature_description text not null,
	#~ start_location smallint not null,
	#~ stop_location smallint not null,
	#~ score_or_evalue real not null,
	#~ status char(1) not null,
	#~ date char(10) not null,
	#~ interpro_id varchar(10),
	#~ interpro_description text,
	#~ go_terms text,
	#~ pathways text
# these fileds will however be despatched between several tables in the SQL database, to avoid redundancy:
# 'protein_infos', 'functional_annotations', 'interpro_terms', 'interpro2GO', 'interpro2pathways'.



def main(dbname, dbengine, interproscanresglobpat, interproscanversion, verbose=False):
	dbcon, dbcur, dbtype, valtoken = get_dbconnection(dbname, dbengine)

	lnfinterproscan = glob.glob(interproscanresglobpat)
	tipv = (interproscanversion,)
	if dbengine=='sqlite':
		dbcon.text_factory = str
		dbcur = dbcon.cursor()
	#~ elif dbengine=='postgres':
		#~ from psycopg2.extras import execute_batch
	# keep track of recorded proteins that may be redundant across the several annotation files (each of which corresponds ot a single proteome)
	srecprot = set([])
	srecip = set([])
	# first record what may already have been loaded in the database
	dbcur.execute("SELECT DISTINCT nr_protein_id FROM functional_annotations WHERE interproscan_version=%s ;"%(valtoken,), tipv)
	srecprot |= set([t[0] for t in dbcur.fetchall()])
	dbcur.execute("SELECT DISTINCT interpro_id FROM interpro_terms ;")
	srecip |= set([t[0] for t in dbcur.fetchall()])

	for nfinterproscan in lnfinterproscan:
		print "parse functional annotations of proteome from file %s"%nfinterproscan
		with open(nfinterproscan, 'r') as finterproscan:
			# first extract lines, filtering those already represented in the protein set
			ltproti = []
			ltannot = []
			ltipacc = []
			ltip2go = []
			ltip2pw = []
			currprotid = None
			for line in finterproscan:
				tsp = tuple(line.rstrip('\n').split('\t'))
				protid = tsp[0]
				if protid != currprotid:
					# assume that all entries for a protein are grouped in one proteome annotation file
					if currprotid: srecprot.add(currprotid)
					currprotid = protid
					# distribute protein description and Interproscan hits into different tables:
					# 'protein_infos'
					ltproti.append(tsp[:3])
				if protid not in srecprot:
					# 'functional_annotations'
					ipscanfileds = tsp[:1]+tsp[3:11]
					if len(tsp)<12:
						ltannot.append(ipscanfileds+(None,)+tipv)
					else:
						ipid = tsp[11]
						ltannot.append(ipscanfileds+(ipid,)+tipv)
						if ipid not in srecip:
							srecip.add(ipid)
							# distribute Interpro accession description and DB cross-references into different tables:
							ipterms = tsp[11:13]
							# 'interpro2GO'
							ip2go = tsp[13]
							if ip2go:
								ipterms += (ip2go,)
								ltip2go += [(ipid, goid) for goid in ip2go.split('|')]
							else:
								ipterms += (None,)
							# 'interpro2pathway'
							ip2pw = tsp[14]
							if ip2pw:
								ipterms += (ip2pw,)
								ltip2pw += [(ipid,)+tuple(pwdbid.split(': ')) for pwdbid in ip2pw.split('|')]
							else:
								ipterms += (None,)
							# 'interpro_terms'
							ltipacc.append(ipterms)
			# completes the record with last protein
			srecprot.add(currprotid)
			# insert data into tables
			lsqlval = [("""INSERT INTO protein_infos 
								 (nr_protein_id, sequence_md5_digest, sequence_length) VALUES (%s,%s,%s);"""%((valtoken,)*3), ltproti), \
					   ("""INSERT INTO functional_annotations 
								 (nr_protein_id, analysis_method, signature_accession, signature_description, 
								 start_location, stop_location, score_or_evalue, analysis_status, analysis_date, 
								 interpro_id, interproscan_version) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);"""%((valtoken,)*11), ltannot), \
					   ("""INSERT INTO interpro_terms
								 (interpro_id, interpro_description, go_terms, pathways) VALUES (%s,%s,%s,%s);"""%((valtoken,)*4), ltipacc), \
					   ("""INSERT INTO interpro2GO
								 (interpro_id, go_id) VALUES (%s,%s);"""%((valtoken,)*2), ltip2go), \
					   ("""INSERT INTO interpro2pathways
								 (interpro_id, pathway_db, pathway_id) VALUES (%s,%s,%s);"""%((valtoken,)*3), ltip2pw) ]
			for sqlstmt, lval in lsqlval:
				#~ if dbengine=='sqlite':
					#~ dbcur.executemany(sqlstmt, lval)
				#~ elif dbengine=='postgres':
					#~ execute_batch(dbcur, sqlstmt, lval, page_size=1000)
				dbcur.executemany(sqlstmt, lval)
			
			print "inserted values into tables: protein_infos, % 5d; functional_annotations, % 5d; interpro_terms, % 5d; interpro2GO, % 5d; interpro2pathway, % 5d."%(len(ltproti), len(ltannot), len(ltipacc), len(ltip2go), len(ltip2pw))

	if dbengine=='sqlite':
		print "%s database total changes:"%dbname, dbcon.total_changes

	indexscript = """CREATE INDEX IF NOT EXISTS funcannot_nrproteinid_idx ON functional_annotations (nr_protein_id);
					 CREATE INDEX IF NOT EXISTS funcannot_analmeth_idx ON functional_annotations (analysis_method);
					 CREATE INDEX IF NOT EXISTS funcannot_sigacc_idx ON functional_annotations (signature_accession);
					 CREATE INDEX IF NOT EXISTS funcannot_method_signacc_idx ON functional_annotations (analysis_method, signature_accession);
					 CREATE UNIQUE INDEX IF NOT EXISTS funcannot_nrproteinid_method_signacc_location_ipversion_uniq ON functional_annotations
					  (nr_protein_id, analysis_method, signature_accession, start_location, stop_location, interproscan_version);
					 CREATE INDEX IF NOT EXISTS funcannot_score_idx ON functional_annotations (score_or_evalue);
					 CREATE INDEX IF NOT EXISTS funcannot_interproid_idx ON functional_annotations (interpro_id);
					 CREATE UNIQUE INDEX IF NOT EXISTS ipterms_interproid_uniq ON interpro_terms (interpro_id);
					 CREATE UNIQUE INDEX IF NOT EXISTS ip2go_interproid_goid_uniq ON interpro2GO (interpro_id, go_id);
					 CREATE INDEX IF NOT EXISTS ip2go_interproid_idx ON interpro2GO (interpro_id);
					 CREATE INDEX IF NOT EXISTS ip2go_goid_idx ON interpro2GO (go_id);
					 CREATE UNIQUE INDEX IF NOT EXISTS ip2pw_interproid_pwdb_pwid_uniq ON interpro2pathways (interpro_id, pathway_db, pathway_id);
					 CREATE INDEX IF NOT EXISTS ip2pw_pwdb_pwid_idx ON interpro2pathways (pathway_db, pathway_id);
					 CREATE INDEX IF NOT EXISTS ip2pw_interproid_idx ON interpro2pathways (interpro_id);
					 CREATE INDEX IF NOT EXISTS ip2pw_pwdb_idx ON interpro2pathways (pathway_db);
					 CREATE INDEX IF NOT EXISTS ip2pw_pwid_idx ON interpro2pathways (pathway_id);"""
					 
					 
	if dbengine=='sqlite':
		dbcur.executescript(indexscript)
	elif dbengine=='postgres':
	indexscript += """		
					 CREATE OR REPLACE VIEW prot2GOterms_oneliner AS
					 SELECT nr_protein_id, string_agg(go_id, '|') AS go_terms
					 FROM (SELECT DISTINCT nr_protein_id, go_id
					  FROM functional_annotations
					  INNER JOIN interpro2GO USING (interpro_id)
					 ) AS dog
					 GROUP BY nr_protein_id;
					 
					 CREATE OR REPLACE VIEW prot2pathways_oneliner AS
					 SELECT nr_protein_id, string_agg(pathway_db_id, '|') AS pathways
					 FROM (SELECT DISTINCT nr_protein_id, concat_ws(':', pathway_db, pathway_id) AS pathway_db_id
					  FROM functional_annotations
					  INNER JOIN interpro2pathways USING (interpro_id)
					 ) AS dpw
					 GROUP BY nr_protein_id;"""
		for sqlline in indexscript.split('\n'):
			dbcur.execute(sqlline)

	print "created indexes as follows: %s"%(indexscript.replace('                 ', ''))

	dbcon.commit()
	dbcon.close()


def usage():
	s = "Usage:\n"
	s += "python %s {--postgresql_db dbname | --sqlite_db dbfile} --ipscan_annot_files inputfile_pathorglobpattern --ipscan_version X.XX-XX.X [OTHER OPTIONS]\n"%sys.argv[0]
	return s

if __name__=='__main__':

	opts, args = getopt.getopt(sys.argv[1:], 'hv', ['postgresql_db=', 'sqlite_db=', 'ipscan_annot_files=', \
	                                                'ipscan_version=', 'help', 'verbose'])
	dopt = dict(opts)
	
	if ('-h' in dopt) or ('--help' in dopt):
		print usage()
		sys.exit(0)

	interproscanresglobpat = dopt['--ipscan_annot_files']
	dbname = dopt.get('--postgresql_db', dopt.get('--sqlite_db'))
	if '--postgresql_db' in dopt:
		dbengine = 'postgres'
	elif '--sqlite_db' in dopt:
		dbengine = 'sqlite'
		raise NotImplementedError, "condensation of coevolution network from gene-lineage to orthologous groups not implement with SQLite database - and unlikely to be so given the huge size of tables to be loaded in memory"
	else:
		raise ValueError, "must provide database name (postgreSQL) / file location (SQLite) through '--sqlite_db' or '--postgresql_db' options"		

	interproscanversion = dopt['--ipscan_version']
	
	verbose = (('-v' in dopt) or ('--verbose' in dopt))

	main(dbname, dbengine, interproscanresglobpat, interproscanversion, verbose)
